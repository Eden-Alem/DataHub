{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /home/lowin/.local/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /usr/lib/python3.10/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in /home/lowin/.local/lib/python3.10/site-packages (from nltk) (1.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/lib64/python3.10/site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in /home/lowin/.local/lib/python3.10/site-packages (from nltk) (4.66.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural language processing library - NLTK in Python\n",
    "import nltk\n",
    "import string\n",
    "from heapq import nlargest\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The main goal of using machine learning for text summarization is to reduce the reference text to a smaller version while keeping its knowledge alongside its meaning. Multiple text summary descriptions are provided, for example, explained the report as text generated from one or more documents that communicate relevant knowledge in the first text, and that is no longer than half of the main text and generally much more limited than this.\"\n",
    "\n",
    "# to determine how many sentences the summary should contain\n",
    "def no_of_sentenes(text):\n",
    "    period_counts = text.count(\". \")\n",
    "    if period_counts > 20:\n",
    "        return int(round(period_counts/10, 0))\n",
    "    \n",
    "    return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The main goal of using machine learning for text summarization is to reduce the reference text to a smaller version while keeping its knowledge alongside its meaning Multiple text summary descriptions are provided for example explained the report as text generated from one or more documents that communicate relevant knowledge in the first text and that is no longer than half of the main text and generally much more limited than this'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(string.punctuation)\n",
    "\n",
    "nopunc =[char for char in text if char not in string.punctuation]\n",
    "nopunc = \"\".join(nopunc)\n",
    "nopunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/lowin/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['main',\n",
       " 'goal',\n",
       " 'using',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'text',\n",
       " 'summarization',\n",
       " 'reduce',\n",
       " 'reference',\n",
       " 'text',\n",
       " 'smaller',\n",
       " 'version',\n",
       " 'keeping',\n",
       " 'knowledge',\n",
       " 'alongside',\n",
       " 'meaning',\n",
       " 'Multiple',\n",
       " 'text',\n",
       " 'summary',\n",
       " 'descriptions',\n",
       " 'provided',\n",
       " 'example',\n",
       " 'explained',\n",
       " 'report',\n",
       " 'text',\n",
       " 'generated',\n",
       " 'one',\n",
       " 'documents',\n",
       " 'communicate',\n",
       " 'relevant',\n",
       " 'knowledge',\n",
       " 'first',\n",
       " 'text',\n",
       " 'longer',\n",
       " 'half',\n",
       " 'main',\n",
       " 'text',\n",
       " 'generally',\n",
       " 'much',\n",
       " 'limited']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# common words that are often removed in text analysis tasks\n",
    "nltk.download('stopwords')\n",
    "\n",
    "processed_text = [word for word in nopunc.split() if word.lower() not in nltk.corpus.stopwords.words('english')]\n",
    "processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'main': 0.42857142857142855,\n",
       "             'goal': 0.2857142857142857,\n",
       "             'using': 0.2857142857142857,\n",
       "             'machine': 0.2857142857142857,\n",
       "             'learning': 0.2857142857142857,\n",
       "             'text': 1.0,\n",
       "             'summarization': 0.2857142857142857,\n",
       "             'reduce': 0.2857142857142857,\n",
       "             'reference': 0.2857142857142857,\n",
       "             'smaller': 0.2857142857142857,\n",
       "             'version': 0.2857142857142857,\n",
       "             'keeping': 0.2857142857142857,\n",
       "             'knowledge': 0.42857142857142855,\n",
       "             'alongside': 0.2857142857142857,\n",
       "             'meaning': 0.2857142857142857,\n",
       "             'Multiple': 0.2857142857142857,\n",
       "             'summary': 0.2857142857142857,\n",
       "             'descriptions': 0.2857142857142857,\n",
       "             'provided': 0.2857142857142857,\n",
       "             'example': 0.2857142857142857,\n",
       "             'explained': 0.2857142857142857,\n",
       "             'report': 0.2857142857142857,\n",
       "             'generated': 0.2857142857142857,\n",
       "             'one': 0.2857142857142857,\n",
       "             'documents': 0.2857142857142857,\n",
       "             'communicate': 0.2857142857142857,\n",
       "             'relevant': 0.2857142857142857,\n",
       "             'first': 0.2857142857142857,\n",
       "             'longer': 0.2857142857142857,\n",
       "             'half': 0.2857142857142857,\n",
       "             'generally': 0.2857142857142857,\n",
       "             'much': 0.2857142857142857,\n",
       "             'limited': 0.2857142857142857})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = defaultdict(lambda: 1)\n",
    "for word in processed_text:\n",
    "    word_freq[word] += 1\n",
    "\n",
    "# normalization scaling the word frequencies between 0 and 1.\n",
    "max_freq = max(word_freq.values())\n",
    "\n",
    "for word in word_freq.keys():\n",
    "    word_freq[word] /= max_freq\n",
    "\n",
    "word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The main goal of using machine learning for text summarization is to reduce the reference text to a smaller version while keeping its knowledge alongside its meaning.', 'Multiple text summary descriptions are provided, for example, explained the report as text generated from one or more documents that communicate relevant knowledge in the first text, and that is no longer than half of the main text and generally much more limited than this.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/lowin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'The main goal of using machine learning for text summarization is to reduce the reference text to a smaller version while keeping its knowledge alongside its meaning.': 6.285714285714285,\n",
       "             'Multiple text summary descriptions are provided, for example, explained the report as text generated from one or more documents that communicate relevant knowledge in the first text, and that is no longer than half of the main text and generally much more limited than this.': 9.714285714285715})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Punkt tokenizer models for sentence tokenization\n",
    "nltk.download('punkt')\n",
    "\n",
    "sent_list = nltk.sent_tokenize(text)\n",
    "print(sent_list)\n",
    "\n",
    "sent_score = defaultdict(int)\n",
    "\n",
    "for sent in sent_list:\n",
    "    for word in nltk.word_tokenize(sent.lower()):\n",
    "        if word in word_freq.keys():\n",
    "            sent_score[sent] += word_freq[word]\n",
    "\n",
    "sent_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Multiple text summary descriptions are provided, for example, explained the report as text generated from one or more documents that communicate relevant knowledge in the first text, and that is no longer than half of the main text and generally much more limited than this.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the length number of sentences with the highest scores from the sent_score dictionary\n",
    "summary_sents = nlargest(no_of_sentenes(text), sent_score, key=sent_score.get)\n",
    "summary = \" \".join(summary_sents)\n",
    "\n",
    "'''\n",
    "Overall it takes an input text, \n",
    "processes it by removing punctuation and common stop words, \n",
    "calculates word frequencies and sentence scores, and \n",
    "generates a summary by selecting the most important sentences based on their scores\n",
    "'''\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
